{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of classification methods for automatic phytolith identification\n",
    "\n",
    "This notebook contains functions and examples to train and evaluate several classifiers using cross validation.\n",
    "\n",
    "The execution of this notebook with a great number of images can take several hours, depending on the machine where it is executed.\n",
    "\n",
    "## Authors\n",
    "- José-Francisco Díez-Pastor\n",
    "- Pedro Latorre-Carmona\n",
    "- Álvar Arnaiz-González\n",
    "- Javier Ruiz-Pérez\n",
    "- Débora Zurro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Perform experiments and examine results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import libraries\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Configuration data\n",
    "'''\n",
    "\n",
    "path = \"./phytoliths\"\n",
    "\n",
    "features_file = path + os.sep + \"features_2020.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features dataset\n",
    "df = pd.read_csv(features_file,index_col=0)\n",
    "\n",
    "y = df.Class.values\n",
    "\n",
    "# Choose only 'Elliptic Fourier Descriptor' feature names\n",
    "efd_cols = df.columns.str.startswith(\"edf\")\n",
    "\n",
    "# EFD Dataset\n",
    "X_efd = df[df.columns[efd_cols]].values\n",
    "\n",
    "# Choose only basic geometric feature names\n",
    "morpho_cols = [\"Perimeter\",\"PerimeterHull\",\"Area\",\"Convex Area\",\"Major axis length\", \n",
    "               \"Minor axis length\",\"Equivalent diameter\",\"Form factor\",\"Length\",\n",
    "               \"Width\",\"Convexity\",\"Solidity\", \"AspectRatio\",\"Roundness\",\"Compactness\"]\n",
    "\n",
    "# Morphological and geometic features Dataset\n",
    "X_morpho = df[morpho_cols].values\n",
    "\n",
    "# All features dataset\n",
    "X_all = np.concatenate((X_morpho, X_efd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of Elliptic Fourier Descriptor dataset\n",
    "X_efd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "List of datasets and their names included in the experimental study\n",
    "'''\n",
    "\n",
    "datasets = [(X_morpho,y), (X_efd,y), (X_all,y)]\n",
    "dataset_names = [\"Data Morpho\", \"Data EFD\", \"Data All\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of the SVM parameter search\n",
    "'''\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid_svm = dict(gamma=gamma_range, C=C_range)\n",
    "nested_cv = 5\n",
    "\n",
    "grid_svm = GridSearchCV(SVC(), param_grid=param_grid_svm, cv=nested_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the range of values to be explored\n",
    "C_range,gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of the MLP parameter search\n",
    "'''\n",
    "alpha_range = np.logspace(-5, -1, 5)\n",
    "hidden_layer_sizes_range=[(50,),(100,),(200,),(500,),(1000,)]\n",
    "\n",
    "param_grid_mlp = dict(alpha=alpha_range, hidden_layer_sizes=hidden_layer_sizes_range)\n",
    "\n",
    "\n",
    "grid_mlp = GridSearchCV(MLPClassifier(max_iter=1000,\n",
    "                                      early_stopping=True), param_grid=param_grid_mlp, cv=nested_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "List of classifiers and their names included in the experimental study\n",
    "'''\n",
    "\n",
    "cls_names = [\"Nearest Neighbors\", \"SVM\", \"Decision Tree\", \"Random Forest\",\"Gradient Boosting Trees\",\"MLP\"]\n",
    "\n",
    "classifiers = [\n",
    "    make_pipeline(StandardScaler(), KNeighborsClassifier(3)),\n",
    "    make_pipeline(StandardScaler(), grid_svm),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0, n_estimators=100),\n",
    "    GradientBoostingClassifier(random_state=0, n_estimators=100),\n",
    "    make_pipeline(StandardScaler(), grid_mlp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_preds_model(X, y, model, num_folds):\n",
    "        '''\n",
    "        Perform cross validation with a model and a dataset (X and y),\n",
    "        and returns the predictions to later obtain the measurements \n",
    "        you want\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: numpy.array\n",
    "            Dataset (features)\n",
    "        Y: numpy.array\n",
    "            Dataset (Target)\n",
    "        model: scikit_model\n",
    "            model to be trained\n",
    "        num_folds: int\n",
    "            number of folds in the cross validation\n",
    "        \n",
    "        Return\n",
    "        -------\n",
    "        array \n",
    "            array of prediccions obtained using cross_validation\n",
    "        '''\n",
    "        print('\\t'+str(model)[:20], end=' - ')\n",
    "        preds = cross_val_predict(model,X,y,cv=num_folds)\n",
    "        print('OK')\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_save(num_folds,filename):\n",
    "    '''\n",
    "    Perform cross validation with all models and datasets.\n",
    "        \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_folds: int\n",
    "        number of folds in the cross validation\n",
    "    filename: string\n",
    "        name of the file that stores the predictions obtained using crossvalidation\n",
    "        \n",
    "    Return\n",
    "    -------\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    all_preds = {}\n",
    "\n",
    "    for dataset,dataset_name in zip(datasets, dataset_names):\n",
    "        print(dataset_name)\n",
    "        X,y = dataset\n",
    "        for model,cls_name in zip(classifiers,cls_names):\n",
    "            print(cls_name)\n",
    "            preds = cross_validate_preds_model(X, y, model, num_folds)\n",
    "            all_preds[(dataset_name,cls_name)]=(y,preds)\n",
    "\n",
    "    all_preds[\"cls_names\"]=cls_names\n",
    "    all_preds[\"dataset_names\"]=dataset_names\n",
    "\n",
    "    with open(filename, 'wb') as fp:\n",
    "         pickle.dump(all_preds, fp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All the predictions are going to be saved in a Python dictionary for \n",
    "further analysis.\n",
    "'''\n",
    "\n",
    "filename3 = 'predicciones3_20.obj'\n",
    "filename5 = 'predicciones5_20.obj'\n",
    "filename10 = 'predicciones10_20.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiments with cv=3 and save\n",
    "run_all_save(3,filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_save(5,filename5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_save(10,filename10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the results\n",
    "\n",
    "If the experiments have been done previously, you only need to execute from this part.\n",
    "\n",
    "The results are going to be loaded from the hard disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_df(cm,labels):\n",
    "    '''\n",
    "    Create a confusion matrix in a DataFrame\n",
    "        \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    cm: ndarray 2D\n",
    "        confusion matrix\n",
    "    labels: list\n",
    "        List of class names\n",
    "        \n",
    "    Return DataFrame\n",
    "    -------\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    return (pd.DataFrame(cm,index=labels, columns=labels)\n",
    "          .rename_axis(\"actual\")\n",
    "          .rename_axis(\"predicted\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (N, M).\n",
    "    row_labels\n",
    "        A list or array of length N with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length M with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A list or array of two color specifications.  The first is used for\n",
    "        values below a threshold, the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = 'predicciones3_20.obj'\n",
    "filename5 = 'predicciones5_20.obj'\n",
    "filename10 = 'predicciones10_20.obj'\n",
    "\n",
    "def get_results(filename):\n",
    "    '''\n",
    "    Load the file with the predictions.\n",
    "    Compute accuracy, confusion matrix and other measures.\n",
    "        \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: string\n",
    "        name of the file that stores the predictions obtained using crossvalidation\n",
    "        \n",
    "    Return\n",
    "    dictionary\n",
    "        A dictionary of key:values that asociates the name\n",
    "        of a measure or chart with the value\n",
    "    -------\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    with open(filename, 'rb') as fp:\n",
    "        all_preds = pickle.load(fp)\n",
    "\n",
    "    cls_names = all_preds.pop(\"cls_names\")\n",
    "    dataset_names = all_preds.pop(\"dataset_names\")\n",
    "\n",
    "    data_cls_pairs = list(all_preds.keys())\n",
    "    data_cls_pairs.sort()\n",
    "\n",
    "    results = {}\n",
    "\n",
    "\n",
    "    acc_df = pd.DataFrame(index=dataset_names, columns=cls_names)\n",
    "\n",
    "    ## A DataFrame is created to store the accuracy in each clase\n",
    "    for dataset in dataset_names:\n",
    "        results[(dataset,\"acc\")] = pd.DataFrame(columns=cls_names)\n",
    "\n",
    "\n",
    "    for dataset_name,cls_name in data_cls_pairs:\n",
    "\n",
    "        #print(dataset_name,cls_name)\n",
    "        y_true, y_pred = all_preds[(dataset_name,cls_name)]\n",
    "        labels = list(np.unique(y_true))\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        # Fill accuracy dataframe\n",
    "        acc_df.at[dataset_name,cls_name]=acc\n",
    "\n",
    "        # Get conf_mat\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        cm_df = conf_mat_df(cm,labels)\n",
    "        results[(dataset_name,cls_name,\"cm\")] = cm_df\n",
    "\n",
    "        # Get classification report\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        results[(dataset_name,cls_name,\"report\")] = report_df\n",
    "\n",
    "        # Acc per class\n",
    "        cm_dig = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_dig = cm_dig.diagonal()\n",
    "\n",
    "        dfi = results[(dataset_name,\"acc\")]\n",
    "        dfi[cls_name]=pd.Series(cm_dig,labels)    \n",
    "        results[(dataset_name,\"acc\")]=dfi.copy()\n",
    "\n",
    "\n",
    "    results[\"Acc\"] = acc_df\n",
    "    return results\n",
    "        \n",
    "        \n",
    "results5 = get_results(filename5)\n",
    "results3 = get_results(filename3)\n",
    "results10 = get_results(filename10)\n",
    "\n",
    "result_dict = {3:results3,5:results5,10:results10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "results = copy.deepcopy(result_dict[5])\n",
    "\n",
    "dropdown_tables = widgets.Dropdown(\n",
    "    options=list(results.keys())+[\"Select one table\"],\n",
    "    value=\"Select one table\",\n",
    "    description='Table:',\n",
    ")\n",
    "\n",
    "dropdown_folds = widgets.Dropdown(\n",
    "    options=[3,5,10],\n",
    "    value=5,\n",
    "    description='Folds:',\n",
    ")\n",
    "\n",
    "lbl = widgets.Label(value=\"\")\n",
    "\n",
    "\n",
    "visor = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_change_table(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        \n",
    "        visor.clear_output()\n",
    "        lbl.value = str(dropdown_folds.value)+\" \"+str(dropdown_tables.value)\n",
    "        with visor:\n",
    "            display(results.get(change['new']))\n",
    "            \n",
    "def on_change_folds(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        \n",
    "        visor.clear_output()\n",
    "        lbl.value = str(dropdown_folds.value)+\" \"+str(dropdown_tables.value)\n",
    "        results = copy.deepcopy(result_dict[change['new']])\n",
    "        with visor:\n",
    "            display(results.get(dropdown_tables.value))\n",
    "        \n",
    "dropdown_tables.observe(on_change_table)\n",
    "dropdown_folds.observe(on_change_folds)\n",
    "\n",
    "box = widgets.VBox([lbl,dropdown_folds, dropdown_tables, visor])\n",
    "\n",
    "display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = results10[\"Acc\"].astype(float)\n",
    "\n",
    "\n",
    "df_conf = results10[(\"Data Morpho\",\"SVM\",\"cm\")].astype(float)\n",
    "df_report = results10[(\"Data Morpho\",\"SVM\",\"report\")].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_total.round(4).to_latex()\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.round(4)[[\"precision\",\"recall\",\"f1-score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Heatmap accuracy\n",
    "'''\n",
    "rows = df_total.index\n",
    "cols =  df_total.columns\n",
    "\n",
    "metric = \"Accuracy\"\n",
    "\n",
    "format_str = \"{x:.4f}\"\n",
    "\n",
    "values = df_total.values\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(False)\n",
    "\n",
    "im, cbar = heatmap(values, rows, cols, ax=ax,\n",
    "                   cmap=\"Blues\", cbarlabel=metric)\n",
    "texts = annotate_heatmap(im, valfmt=format_str)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"totals.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Confusion Matrix\n",
    "'''\n",
    "\n",
    "rows = df_conf.index\n",
    "cols =  df_conf.columns\n",
    "\n",
    "metric = \"Count\"\n",
    "\n",
    "format_str = \"{x:}\"\n",
    "\n",
    "values = df_conf.values.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(False)\n",
    "\n",
    "im, cbar = heatmap(values, rows, cols, ax=ax,\n",
    "                   cmap=\"Blues\", cbarlabel=metric)\n",
    "texts = annotate_heatmap(im, valfmt=format_str)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"Conf_mat.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
